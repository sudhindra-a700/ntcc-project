# -*- coding: utf-8 -*-
"""fraud_detection_verified.py (Updated for more verification fields)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ROzoJARrtPxWq6W7ZGEv_YZx5iaZ-N7
"""

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
from datasets import load_dataset, Dataset
import shap
import numpy as np
import pandas as pd
import os
import re
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
import requests
import json
from datetime import datetime
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Load tokenizer and model
model_name = "distilbert-base-uncased"
output_dir = "./distilbert-fraud-finetuned"

# Initialize tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_name)
if os.path.exists(output_dir):
    model = AutoModelForSequenceClassification.from_pretrained(output_dir, num_labels=2)
else:
    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)

def verify_organization_india(org_name: str, pan: Optional[str] = None, reg_number: Optional[str] = None,
                              registration_type: Optional[str] = None, ngo_darpan_id: Optional[str] = None,
                              fcra_number: Optional[str] = None, api_key_trustcheckr: Optional[str] = None) -> dict:
    """
    Verify an Indian organization using government and third-party platforms.
    This is a mock implementation. For a real application, integrate with actual APIs.

    Args:
        org_name (str): Name of the organization.
        pan (str): PAN number (optional).
        reg_number (str): Registration number (optional, used for CIN/Society/Trust).
        registration_type (str): Type of registration (e.g., "Section 8 Company", "Society", "Trust").
        ngo_darpan_id (str): NGO Darpan Unique ID (optional).
        fcra_number (str): FCRA registration number (optional).
        api_key_trustcheckr (str): TrustCheckr API key (optional).

    Returns:
        dict: Verification results and status.
    """
    verification_results = {
        'org_name': org_name,
        'mca_status': 'Unknown',
        'ngo_darpan_status': 'Unknown',
        'pan_status': 'Unknown',
        'society_status': 'Unknown',
        'trust_status': 'Unknown',
        'fcra_status': 'Unknown',
        'trustcheckr_score': None,
        'social_media_verified': False,
        'issues': []
    }

    # Mock PAN verification
    if pan:
        if len(pan) == 10 and pan.isalnum() and pan.isupper(): # Basic format check
            verification_results['pan_status'] = 'Verified'
        else:
            verification_results['pan_status'] = 'Invalid/Not Found'
            verification_results['issues'].append('Invalid PAN format')

    # Mock MCA (Ministry of Corporate Affairs) check for Section 8 Company
    if registration_type == "Section 8 Company" and reg_number:
        if reg_number.startswith("U") and len(reg_number) == 21: # Mock CIN format
            verification_results['mca_status'] = 'Active'
        else:
            verification_results['mca_status'] = 'Not Found'
            verification_results['issues'].append('MCA registration not found or invalid format')

    # Mock NGO Darpan verification
    if ngo_darpan_id:
        if ngo_darpan_id.startswith("UP") and len(ngo_darpan_id) == 12: # Mock NGO Darpan ID format
            verification_results['ngo_darpan_status'] = 'Registered'
        else:
            verification_results['ngo_darpan_status'] = 'Not Registered/Invalid ID'
            verification_results['issues'].append('NGO Darpan ID not found or invalid')

    # Mock FCRA verification
    if fcra_number:
        if fcra_number.isdigit() and len(fcra_number) == 10: # Mock FCRA format
            verification_results['fcra_status'] = 'Registered'
        else:
            verification_results['fcra_status'] = 'Not Registered/Invalid FCRA'
            verification_results['issues'].append('FCRA registration not found or invalid')

    # Mock Society/Trust registration check
    if registration_type in ["Society", "Trust"] and reg_number:
        if reg_number.startswith("S") or reg_number.startswith("T"): # Simple mock for society/trust reg
            if registration_type == "Society":
                verification_results['society_status'] = 'Registered'
            else:
                verification_results['trust_status'] = 'Registered'
        else:
            if registration_type == "Society":
                verification_results['society_status'] = 'Not Registered'
            else:
                verification_results['trust_status'] = 'Not Registered'
            verification_results['issues'].append(f'{registration_type} registration not found or invalid format')


    # Mock TrustCheckr API call
    if api_key_trustcheckr and api_key_trustcheckr != "mock_trustcheckr_key":
        # In a real scenario, you'd make an actual API call here.
        # For demonstration, we'll return a mock score based on presence of key info.
        mock_score = 0.5 # Default
        if verification_results['pan_status'] == 'Verified':
            mock_score -= 0.1
        if verification_results['mca_status'] == 'Active' or verification_results['ngo_darpan_status'] == 'Registered':
            mock_score -= 0.2
        if len(verification_results['issues']) > 0:
            mock_score += 0.3 # Increase score for issues
        verification_results['trustcheckr_score'] = max(0.0, min(1.0, mock_score)) # Keep between 0 and 1
    else:
        # If no real API key, provide a default mock score
        verification_results['trustcheckr_score'] = random.uniform(0.1, 0.9) # Random score for mock

    # Mock social media verification (always True for simplicity unless issues are found)
    if not verification_results['issues']:
        verification_results['social_media_verified'] = True
    else:
        verification_results['social_media_verified'] = False


    return verification_results

# Define the dataset path globally or pass it
dataset_path = "ngo_fraud.csv"

# Dummy dataset for fine-tuning if the actual file is not available
if not os.path.exists(dataset_path):
    print(f"Warning: {dataset_path} not found. Creating a dummy dataset for fraud detection model.")
    dummy_data = {
        'text': [
            "Legitimate charity raising funds for education.",
            "Invest now for guaranteed 100% returns in 24 hours!",
            "Building sustainable communities through local initiatives.",
            "Urgent! Send money to this account for a secret prize.",
            "Non-profit organization dedicated to environmental conservation.",
            "Double your money with our exclusive crypto scheme.",
            "Supporting local artists and cultural events.",
            "Click this suspicious link for free bitcoins.",
            "Community garden project needs volunteers and donations.",
            "Get rich quick with zero effort. Limited time offer!"
        ],
        'label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1] # 0 for legitimate, 1 for fraud
    }
    dummy_df = pd.DataFrame(dummy_data)
    dummy_df.to_csv(dataset_path, index=False)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

def fine_tune_model(dataset_path="social_media_fraud.csv", k_folds=3):
    """
    Fine-tunes the DistilBERT model for fraud detection.
    Uses k-fold cross-validation.
    """
    if os.path.exists(output_dir) and os.listdir(output_dir):
        print("Model already fine-tuned. Skipping fine-tuning.")
        return

    print(f"Loading dataset from {dataset_path}...")
    try:
        df = pd.read_csv(dataset_path)
    except FileNotFoundError:
        print(f"Error: Dataset file not found at {dataset_path}. Cannot fine-tune model.")
        return

    # Ensure 'text' and 'label' columns exist
    if 'text' not in df.columns or 'label' not in df.columns:
        print("Error: Dataset must contain 'text' and 'label' columns.")
        return

    dataset = Dataset.from_pandas(df)
    tokenized_dataset = dataset.map(tokenize_function, batched=True)

    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

    # Simple accuracy metric
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        return {"accuracy": (predictions == labels).mean()}

    for fold, (train_index, val_index) in enumerate(kf.split(tokenized_dataset)):
        print(f"--- Training Fold {fold+1}/{k_folds} ---")
        train_dataset = tokenized_dataset.select(train_index)
        val_dataset = tokenized_dataset.select(val_index)

        training_args = TrainingArguments(
            output_dir=f"./results_fold_{fold}",
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir=f"./logs_fold_{fold}",
            logging_steps=10,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="accuracy",
            report_to="none" # Disable reporting to external services like wandb
        )

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=compute_metrics,
        )

        trainer.train()
        print(f"Finished training fold {fold+1}.")

    # Save the final fine-tuned model
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    print(f"Fine-tuned model saved to {output_dir}")


def predict_fraud(organization_data: dict, api_key_trustcheckr: Optional[str] = None) -> tuple:
    """
    Predicts fraud score and provides explanation for an organization.
    Integrates with mock TrustCheckr and other verification services.
    """
    text = organization_data.get('recent_posts', '') + " " + organization_data.get('bio', '')

    # Tokenize input text for model prediction
    inputs = tokenizer(text, return_tensors="pt", padding="max_length", truncation=True)

    # Ensure the model is loaded
    if not os.path.exists(output_dir) or not os.listdir(output_dir):
        print("Warning: Model not fine-tuned. Using dummy prediction.")
        # Dummy prediction if model is not fine-tuned
        fraud_score = random.uniform(0.0, 1.0)
        explanation = "Model not fine-tuned. Dummy fraud prediction."
        plot_path = "dummy_shap_plot.png" # Placeholder

        # Call mock verification service
        verification = verify_organization_india(
            org_name=organization_data.get('org_name', 'N/A'),
            pan=organization_data.get('pan'),
            reg_number=organization_data.get('registration_number'),
            registration_type=organization_data.get('registration_type'),
            ngo_darpan_id=organization_data.get('ngo_darpan_id'),
            fcra_number=organization_data.get('fcra_number'),
            api_key_trustcheckr=api_key_trustcheckr
        )
        return fraud_score, explanation, plot_path, verification

    # Model prediction
    model.eval()
    with torch.no_grad():
        logits = model(**inputs).logits
    probabilities = torch.softmax(logits, dim=1)[0]
    fraud_score = probabilities[1].item() # Probability of being fraud (label 1)

    # Generate explanation using SHAP (simplified for text input)
    # This part might be computationally intensive and requires a proper explainer setup.
    # For a simple text input, SHAP on token embeddings is more complex.
    # We'll provide a rule-based explanation for now based on the score.

    explanation = "AI analysis based on text content and organizational data. "
    if fraud_score > 0.7:
        explanation += "High likelihood of fraud detected. Suspicious language patterns and/or lack of verifiable organizational details contribute to this score."
    elif fraud_score > 0.4:
        explanation += "Moderate risk of fraud detected. Some inconsistencies or less verifiable information were found. Manual review is recommended."
    else:
        explanation += "Low likelihood of fraud. Information appears consistent and verifiable."

    # Incorporate numerical features for a more comprehensive score if available
    # For now, we'll stick to text-based explanation and mock numerical influence.
    numerical_features = {
        'follower_count': organization_data.get('follower_count', 0),
        'post_count': organization_data.get('post_count', 0),
        'account_age_days': organization_data.get('account_age_days', 0),
        'engagement_rate': organization_data.get('engagement_rate', 0.0)
    }

    # Call mock verification service with all relevant details
    verification = verify_organization_india(
        org_name=organization_data.get('org_name', 'N/A'),
        pan=organization_data.get('pan'),
        reg_number=organization_data.get('registration_number'),
        registration_type=organization_data.get('registration_type'),
        ngo_darpan_id=organization_data.get('ngo_darpan_id'),
        fcra_number=organization_data.get('fcra_number'),
        api_key_trustcheckr=api_key_trustcheckr
    )

    # Adjust fraud score based on verification results (mock logic)
    if verification['pan_status'] == 'Invalid/Not Found' or \
       verification['mca_status'] == 'Not Found' or \
       verification['ngo_darpan_status'] == 'Not Registered/Invalid ID' or \
       verification['fcra_status'] == 'Not Registered/Invalid FCRA':
        fraud_score = min(1.0, fraud_score + 0.2) # Increase fraud score if core verifications fail
        explanation += " Critical verification details (PAN/MCA/NGO Darpan/FCRA) could not be confirmed."

    if verification['trustcheckr_score'] is not None:
        # Blend TrustCheckr score with model's text-based score
        fraud_score = (fraud_score * 0.6) + (verification['trustcheckr_score'] * 0.4)
        explanation += f" TrustCheckr score: {verification['trustcheckr_score']:.2f}."

    # Final fraud score clamping
    fraud_score = max(0.0, min(1.0, fraud_score))

    # Mock SHAP plot path (real SHAP generation requires more setup)
    plot_path = f"shap_plot_{organization_data.get('org_name', 'unknown')}.png"
    # In a real scenario, you'd generate and save the SHAP plot here.
    # For now, we'll just return a placeholder path.
    plt.figure(figsize=(1,1)) # Create a tiny dummy figure to avoid matplotlib warnings if not used
    plt.close()

    return fraud_score, explanation, plot_path, verification

if __name__ == "__main__":
    # Fine-tune model
    # Ensure social_media_fraud.csv exists or is created by the dummy data logic
    fine_tune_model(dataset_path="social_media_fraud.csv", k_folds=1) # Reduced folds for quicker local test

    # Example prediction
    sample_org_legit = {
        'org_name': 'EcoFuture Solutions',
        'bio': 'Dedicated to developing sustainable technologies for a greener planet.',
        'follower_count': 10000,
        'post_count': 200,
        'account_age_days': 730,
        'engagement_rate': 0.03,
        'recent_posts': 'Join our tree planting drive next month!',
        'pan': 'ABCDE1234F',
        'registration_type': 'Section 8 Company',
        'registration_number': 'U12345ABCDE67890FGHIJ',
        'ngo_darpan_id': 'UP1234567890',
        'fcra_number': '1234567890'
    }
    fraud_score, explanation, plot_path, verification = predict_fraud(sample_org_legit, api_key_trustcheckr="test_key")
    print("\n--- Legit Organization Prediction ---")
    print(f"Fraud Score: {fraud_score:.2f}")
    print(f"Explanation: {explanation}")
    print(f"Verification: {json.dumps(verification, indent=2)}")

    sample_org_fraud = {
        'org_name': 'CryptoGold Investments',
        'bio': 'Guaranteed daily returns! Invest in our exclusive crypto arbitrage bots.',
        'follower_count': 50,
        'post_count': 5,
        'account_age_days': 10,
        'engagement_rate': 0.1,
        'recent_posts': 'Last chance to get rich! DM us now!',
        'pan': 'INVALIDPAN12',
        'registration_type': '', # No specific type
        'registration_number': '',
        'ngo_darpan_id': '',
        'fcra_number': ''
    }
    fraud_score, explanation, plot_path, verification = predict_fraud(sample_org_fraud, api_key_trustcheckr="test_key")
    print("\n--- Fraudulent Organization Prediction ---")
    print(f"Fraud Score: {fraud_score:.2f}")
    print(f"Explanation: {explanation}")
    print(f"Verification: {json.dumps(verification, indent=2)}")